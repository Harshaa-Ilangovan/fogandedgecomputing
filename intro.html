<!DOCTYPE html>
<html lang="en" scroll-behavior="smooth">
<head>
    <link rel="stylesheet" href="intro.css">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to fog and edge</title>
</head>
<body>
    <div id="sectionintro">
        <video playsinline autoplay muted loop style="height:500vh;"><source src="video/video.mp4" type="video/mp4"></video>
<div class="introcard">
    
    <h2 style="color: rgb(255, 64, 0);">INTRODUCTION</h2>
    <p class="p1">Accessing remote computing resources offered by cloud data centers has become the <b>de facto</b> model for most Internet-based applications. Typically, data generated by user devices such as smartphones and wearables, or sensors in a smart city or factory are all transferred to geographically distant clouds to be processed and stored. This computing model is not practical for the future, because it is likely to increase <b>communication latencies</b> when billions of devices are connected to the Internet.Applications will be adversely impacted because of the increase in communication latencies, thereby degrading the overall <b>Quality-of-Service (QoS) and Quality-of-Experience (QoE)</b> .An alternative computing model that can alleviate the above problem is bringing computing resources closer to user devices and sensors, and using them for data processing (even if only partial) . This would reduce the amount of data sent to the cloud, consequently reducing communication latencies. To realize this computing model, the current research trend is to decentralize some of the computing resources available in large data centers by distributing them towards the edge of the network closer to the end-users and sensors. These resources may take the form of either 
    </p>
      <p class="p2">(i) dedicated “micro” data centers that are conveniently and safely located within public/private infrastructure </p>
      <p class="p2"> (ii) Internet nodes, such as routers, gateways, and switches that are augmented with computing capabilities. </p>
      <p class="p1">A computing model that makes use of resources located at the edge of the network is referred to as “edge computing” . A model that makes use of both edge resources and the cloud is referred to as “fog computing”.
        Contrary to cloud resources, the resources at the edge are:  </p>
        <p class="p2">(i) resource constrained—limited computational resources, because edge devices have smaller processors and a limited power budget,</p>
         <p  class="p2"> (ii) heterogeneous—processors with different architectures, and </p>
          <p  class="p2">(iii) dynamic—their workloads change, and applications compete for the limited resources. </p>
          <p  class="p1">Therefore, managing resources is one of the key challenges in fog and edge computing. The focus of this article is to review the architectures, infrastructure, and algorithms that underpin resource management in fog/edge computing.</p>
          <img src="image/intro1.png" style="height:60vh; width:60vw; padding:10px;"/>
          <div>
            <button class="button" style="margin-top:5vh;" onclick="display('sectionfog')">FOG COMPUTING</button>
          </div>
          <div id="sectionfog">
            <p class="p1"><b> Fog computing</b></p>
                  
            <p class="p1"> Fog computing bridges the gap between the cloud and end devices
             (e.g., IoT nodes) by enabling computing, storage, networking, and data
             management on network nodes within the close vicinity of IoT devices.
             Consequentially, computation, storage, networking, decision makingand data management not only occur in the cloud, but also occur along
             the IoT-to-Cloud path as data traverses to the cloud (preferably close to
             the IoT devices). For instance, compressing the GPS data can happen at
             the edge before transmission to the cloud in Intelligent Transportation
             Systems (ITS) . Fog computing is defined by the OpenFog Consor-
             tium  as “a horizontal system-level architecture that distributes com-
             puting, storage, control and networking functions closer to the users
             along a cloud-to-thing continuum.” The “horizontal” platform in fog
             computing allows computing functions to be distributed between dif-
             ferent platforms and industries, whereas a vertical platform promotes
             siloed applications. A vertical platform may provide strong sup-
             port for a single type of application (silo), but it does not account for
             platform-to-platform interaction in other vertically focused platforms.
             In addition to facilitating a horizontal architecture, fog computing pro-
             vides a flexible platform to meet the data-driven needs of operators and
             users. Fog computing is intended to provide strong support for the In-
             ternet of Things.</p>
             <p class="p1"><b>Fog vs. cloud</b></p>
             <p class="p1"> 
             A common example that is often used to distinguished fog and cloud
             computing is whether latency-sensitive applications can be supported
             while maintaining satisfactory quality of service (QoS). Fog nodes can
             be placed close to IoT source nodes, allowing latency to be noticeably
             reduced compared to traditional cloud computing. While this example
             gives an intuitive motivation for fog, latency-sensitive applications are
             only one of the many applications that warrant the need for fog com-
             puting. Nodes in fog computing are generally deployed in less central-
             ized locations compared to centralized cloud data centers. Fog nodes
             are wide-spread and geographically available in large numbers. In fog
             computing, security must be provided at the edge or in the dedicated
             locations of fog nodes, as opposed to the centrally-developed security
             mechanisms in dedicated buildings for cloud data centers. The decen-
             tralized nature of fog computing allows devices to either serve as fog
             computing nodes themselves (e.g. a car acts as a fog node for onboard
             sensors) or use fog resources as the clients of the fog.
             The majority of differences between cloud and fog computing are
             attributed to the scale of hardware components associated with these
             computing paradigms. Cloud computing provides high availability of
             computing resources at relatively high power consumption, whereas
             fog computing provides moderate availability of computing resources
             at lower power consumption. Cloud computing typically utilizes
             large data centers, whereas fog computing utilizes small servers, routers,
             switches, gateways, set-top boxes, or access points. Since hardware for
             fog computing occupies much less space than that of cloud computing,
             hardware can be located closer to users. Fog computing can be accessed
             through connected devices from the edge of the network to the network
             core, whereas cloud computing must be accessed through the network
             core. Moreover, continuous Internet connectivity is not essential for the
             fog-based services to work. That is, the services can work independently
             with low or no Internet connectivity and send necessary updates to the
             cloud whenever the connection is available. Cloud computing, on the
             other hand, requires devices to be connected when the cloud service is
             in progress.
             Fog helps devices measure, monitor, process, analyze, and react, and
             distributes computation, communication, storage, control, and decision
             making closer to IoT devices. Many industries could
             use fog to their benefit: energy, manufacturing, transportation, health-
             care, smart cities, to mention a few.</p>
             <div class="card2"><img src="image/intro2.png" alt="f6"></div>
             <div class="card2"><img src="image/intro3.png" alt="f7"></div>
             <p class="p1"><b>Fogcloud federation</b></p>
             
             <p class="p1">There are clear differences and trade-offs between cloud and fog
             computing, and one might ask which one to choose. However, fog and
             cloud complement each other; one cannot replace the need of the other.
             By coupling cloud and fog computing, the services that connected de-
             vices use can be optimized even further. Federation between fog and
             cloud allows enhanced capabilities for data aggregation, processing, and
             storage. For instance, in a stream processing application, the fog could
             filter, preprocess, and aggregate traffic streams from source devices,
             while queries with heavy analytical processing, or archival results could
             be sent to the cloud. An orchestrator could handle the cooperation be-
             tween cloud and fog. Specifically, a fog orchestrator could provide an in-
             teroperable resource pool, deploy and schedule resources to application
             workflows, and control QoS. Through the use of SDN, fog service
             providers will have greater control over how the network is configured
             with a large number of fog nodes that transfer data between the cloud
             and IoT devices.</p>
             <p class="p1"><b>Fog RAN</b></p>
             <p class="p1">
             Fog computing can be integrated into mobile technologies in the
             form of radio access networks (RAN), to form what is referred to as fog
             RAN (F-RAN). Computing resources on F-RANs may be used for caching
             at the edge of the network, which enables faster retrieval of content and
             a lower burden on the front-haul. F-RAN can be implemented through
             5G related mobile technologies. On the other hand, cloud RAN
             (C-RAN) provides centralized control over F-RAN nodes. C-RAN takes
             advantage of virtualization, and decouples the base stations within a
             cell of the mobile network from its baseband functions by virtualizing
             those functions. In C-RAN a large number of low-cost Remote Ra-
             dio Heads (RRHs) are randomly deployed and connected to the Base
             Band Unit (BBU) pool through the front-haul links. Both F-RAN and
             C-RAN are suited for mobile networks with base stations and are can-
             didates for 5G deployments. Also, the use of F-RAN and C-RAN brings
             a more energy efficient form of network operation. We encourage the
             motivated reader to refer to reference for more information about
             F-RAN.</p>
             </div>
          </div>
        </div>
        
           
           
        
</div>
    </div>
    <script type="text/javascript" src="https://d1tgh8fmlzexmh.cloudfront.net/ccbp-static-website/js/ccbp-ui-kit.js">
    </script>
    <script>
        var video=document.getElementById("myvideo");
    </script>
</body>
</html>